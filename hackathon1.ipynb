{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsfnS9Oql94ebRDqBiUtpP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coldsober-irene/hackathon1/blob/main/hackathon1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VVznFQk0ndVF"
      },
      "outputs": [],
      "source": [
        "# REQUIRED IMPORTS\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA MINING\n",
        "class dataMining:\n",
        "  def __init__(self, jobSource = \"Job In Rwanda\"):\n",
        "    self.source = jobSource\n",
        "    self.jobIdentification = {} # {\"software_developer\":[published_date, company, requirements, deadline, full_description],....}\n",
        "  \n",
        "  # SOUP\n",
        "  def Soup(self, url):\n",
        "    page = requests.get(url).content\n",
        "    soup = bs(page, \"html.parser\")\n",
        "    return soup\n",
        "\n",
        "  def get_links(self):\n",
        "    # GET SOUP OBJECT\n",
        "    soup = self.Soup(url = \"https://www.jobinrwanda.com/jobs/all\")\n",
        "    # GET ALL JOBS LINKS\n",
        "    company_infoLink = []\n",
        "    all_jobsLinks = [\"https://www.jobinrwanda.com\"+link['href'] if \"job\" in link['href'] else company_infoLink.append(\"https://www.jobinrwanda.com\"+link['href']) for div in soup.find_all(\"div\", class_= \"card-body p-2\") for link in div.find_all(\"a\")]\n",
        "    all_jobsLinks = [link for link in all_jobsLinks if link]\n",
        "    return (all_jobsLinks, company_infoLink)\n",
        "\n",
        "  def get_content(self):\n",
        "    jobLinks = self.get_links()[0]\n",
        "    # j = []\n",
        "    for url in jobLinks:\n",
        "      soup = self.Soup(url)\n",
        "      # job_info = [ul for div in soup.find('div', class_='card-body') for ul in div.find_all(\"ul\", class_ = \"list-group-flush\")]\n",
        "      pattern = re.compile(\"\\s{2,}\")\n",
        "      job_info = [pattern.sub(\" \",li.text.strip().replace(\"\\n\", \"\")) for ul in soup.find_all('ul', class_ = \"list-group list-group-flush\") for li in ul.find_all('li')]\n",
        "      print(json.dumps(job_info))\n",
        "\n",
        "jobInRwanda = dataMining()\n",
        "jobInRwanda.get_content()"
      ],
      "metadata": {
        "id": "FHrZBDzxnr2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA SORTING"
      ],
      "metadata": {
        "id": "J_FyJUHenxcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA PRESENTATION"
      ],
      "metadata": {
        "id": "OiOwDk__n0NH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}