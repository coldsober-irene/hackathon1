{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/coldsober-irene/hackathon1/blob/main/Copy_of_hackathon1.ipynb",
      "authorship_tag": "ABX9TyMsCmaeE+TrcN7cqR2ESnuU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coldsober-irene/hackathon1/blob/main/Copy_of_hackathon1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  -U easynmt"
      ],
      "metadata": {
        "id": "odThOZlgRGDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install uvicorn fastapi"
      ],
      "metadata": {
        "id": "ekI_iYhwv5qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi pyngrok uvicorn nest-asyncio"
      ],
      "metadata": {
        "id": "kabEbcfT01CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "id": "wE4qyx7H0Bw9",
        "outputId": "6f21e3ae-789f-4dea-d48b-36ce344d59c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.10.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# config the account\n",
        "!ngrok authtoken 2HJPvK5e4VxcduBjO5XSc0LqqCR_5zV3b5gBcKuNMUnxdpfuP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3EGrszK1AJc",
        "outputId": "8669bc26-1680-4fe5-eefd-d1109931f23d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "VVznFQk0ndVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "482fa96e-4e59-42d0-ab94-f79456830388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# REQUIRED IMPORTS\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "from easynmt import EasyNMT\n",
        "import json # to access languages codes\n",
        "from fastapi import FastAPI, Response\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the default limit of pandas columns to display\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ],
      "metadata": {
        "id": "HoCXzoUQwdCP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% **WEBSCRAPING SECTION** %%%%%%%%%%%%%%%%%%%%%"
      ],
      "metadata": {
        "id": "sf_tJz_GQfY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "edGah2eCV3tU"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA MINING\n",
        "class dataMining:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "    \n",
        "  # SOUP\n",
        "  def Soup(self, url):\n",
        "    return bs(requests.get(url).content, \"html.parser\")\n",
        "  \n",
        "  def get_text(self):\n",
        "    soup = self.Soup(url = 'https://www.jobinrwanda.com/jobs/featured')\n",
        "    parent = \"https://www.jobinrwanda.com\"\n",
        "    co_links = {}\n",
        "    app_link = []\n",
        "    full_text = [[(p.get_text(), self.Soup(j_link).find(\"a\", class_ = \"btn btn-sm btn-success\")) for p in dv.find_all('p', class_ = 'text-align-justify')] for j_link in [job_link for job_link in [parent+link['href'] if '/job/' in link['href'] else co_links.setdefault(link.text, parent+link['href']) \n",
        "    for div in soup.find_all('div', class_ = 'card-body p-2')[4] for link in div.find_all('a')] if '/job/' in job_link]\n",
        "    for dv in self.Soup(j_link).find_all('div', class_ = \"clearfix text-formatted field field--name-field-job-full-description field--type-text-long field--label-hidden field__item\")\n",
        "    ]\n",
        "    return (full_text, app_link)\n",
        "\n",
        "  def get_links(self):\n",
        "    # GET SOUP OBJECT\n",
        "    # soup = self.Soup(url = \"https://www.jobinrwanda.com/jobs/all\")\n",
        "    soup = self.Soup(url = 'https://www.jobinrwanda.com/jobs/featured')\n",
        "    # GET ALL JOBS LINKS\n",
        "    company_infoLink = []\n",
        "    \n",
        "    all_jobsLinks = [\"https://www.jobinrwanda.com\"+link['href'] if \"job\" in link['href'] \n",
        "                     else company_infoLink.append(link.text) \n",
        "                     for div in soup.find_all(\"div\", class_= \"card-body p-2\") \n",
        "                     for link in div.find_all(\"a\")\n",
        "                     ]\n",
        "    all_jobsLinks = [link for link in all_jobsLinks if link]\n",
        "    return (all_jobsLinks, company_infoLink)\n",
        "\n",
        "  def get_jobInfo(self):\n",
        "    jobLinks = self.get_links()[0]\n",
        "    info = {}\n",
        "    # REFINE THE INFO INTO A DICTIONARY\n",
        "    def refine_info(ls):\n",
        "      refined_info = {}\n",
        "      infoZeroPattern = re.compile(\"\\d+.*\")\n",
        "      views = infoZeroPattern.search(ls[0]).group()\n",
        "      refined_info[\"views\"] = views\n",
        "      # OTHER DETAILS EXCEPT THE ONE ON POSITION 0\n",
        "      otherInfoPattern = re.compile(\":\")\n",
        "      for detail in ls[1:]:\n",
        "        if detail.lower() == \"apply\":\n",
        "          pass\n",
        "        else:\n",
        "          try:\n",
        "            detailed = otherInfoPattern.split(detail)\n",
        "            refined_info[detailed[0]] = detailed[1]\n",
        "          except IndexError:\n",
        "            pass\n",
        "      return refined_info\n",
        "       \n",
        "    for index,url in enumerate(jobLinks):\n",
        "      soup = self.Soup(url)\n",
        "      pattern = re.compile(\"\\s{2,}\")\n",
        "      job_info = [pattern.sub(\" \",li.text.strip().replace(\"\\n\", \"\")) for ul in soup.find_all('ul', class_ = \"list-group list-group-flush\") \n",
        "      for li in ul.find_all('li')]\n",
        "      # DICTIONANRY OF INFO\n",
        "      info[index] = refine_info(job_info[:9])\n",
        "    return info\n",
        "\n",
        "  def get_description(self):\n",
        "    jobLinks = self.get_links()[0]\n",
        "    all_text= {}\n",
        "    for index,link in enumerate(jobLinks):\n",
        "      soup = self.Soup(link)\n",
        "      # JOB TITLE\n",
        "      job_title = soup.find('span', class_ = \"field field--name-title field--type-string field--label-hidden\")\n",
        "      \n",
        "      tags_content = soup.find_all('div', class_= \"clearfix text-formatted field field--name-field-job-full-description field--type-text-long field--label-hidden field__item\")\n",
        "      \n",
        "      for div in tags_content:\n",
        "        temp = []\n",
        "        try:\n",
        "          # GET APPLICATION LINK\n",
        "          app_link = soup.find(\"a\", class_ = \"btn btn-sm btn-success\")['href']\n",
        "          if app_link.startswith(\"/\"):\n",
        "            app_link = \"https://www.jobinrwanda.com\"+app_link\n",
        "          temp.append(app_link)\n",
        "          \n",
        "        except TypeError:\n",
        "          temp.append(np.nan)\n",
        "        for tag in div.children:\n",
        "          try:\n",
        "            temp.append(tag.get_text())\n",
        "          except (AttributeError, TypeError):\n",
        "            pass\n",
        "        temp.insert(0, job_title.text)\n",
        "        all_text[index] = temp\n",
        "    return all_text"
      ],
      "metadata": {
        "id": "FHrZBDzxnr2Q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MERGE JOB DESCRIPTION WITH THE JOB INFO\n",
        "def final_textDemo():\n",
        "  global info\n",
        "  # CLASS OBJECT CREATION\n",
        "  jobInRwanda = dataMining()\n",
        "  job_text = jobInRwanda.get_description()\n",
        "  info = jobInRwanda.get_jobInfo()\n",
        "\n",
        "  final_demo = []\n",
        "  for index in list(info.keys()):\n",
        "    try:\n",
        "      info_value = list(info[index].values())\n",
        "      # ADD COMPANY HIRING\n",
        "      co_info = jobInRwanda.get_links()[1]\n",
        "      info_value.append(co_info[index])\n",
        "      # INCLUDE JOB TITLE\n",
        "      info_value.append(job_text[index][0])\n",
        "      # INCLUDE APPLY LINK\n",
        "      info_value.append(job_text[index][1])\n",
        "      # JOIN PARAGRAPHS \n",
        "      t = '\\n'.join(job_text[index][2:])\n",
        "      g = re.compile(\"\\n|\\\\xa0\").sub(\"\", t)\n",
        "      info_value.append(g)\n",
        "      final_demo.append(info_value)\n",
        "    except KeyError:\n",
        "      pass\n",
        "  return final_demo\n",
        "# FUNCTION CALL\n",
        "final_content = final_textDemo()"
      ],
      "metadata": {
        "id": "6M1vZYI28KaD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FORM DATAFRAME\n",
        "titles = list(info[0].keys()) + [\"Company Hiring\",'Job Title', \"Application link\", \"Job Description\"]\n",
        "len(final_content[0])\n",
        "# , titles\n",
        "df = pd.DataFrame(data = final_content, columns = titles)\n"
      ],
      "metadata": {
        "id": "zlSrP6K6w6ZR"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GET IT & COMPUTER RELATED JOBS, INTERNERSHIPS AND CONSULTANCY"
      ],
      "metadata": {
        "id": "lOEIQ6Ac2ypT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare kewords IT & COMPUTER jobs\n",
        "IT_keywords = \"\"\"\n",
        "                #informationtechnology #technology #it #cybersecurity #tech #computerscience #programming #business #coding #innovation #software #python #information #computer #informationsecurity #security #technologynews #java #networking #hacking #programmer #linux #technologyrocks #coder #technologythesedays #cloudcomputing #education #engineering #itservices #newtechnology\n",
        "              \"\"\".split('#')[1:-2]\n",
        "# print(IT_keywords)\n",
        "IT_keywords[2] = IT_keywords[2].upper()\n",
        "keywords = re.sub('\\s',\"\",\"|\".join(IT_keywords))"
      ],
      "metadata": {
        "id": "hUMeaa9NdE2k"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = {'Job Description':keywords, 'Sector':'Computer|IT'}\n",
        "df2 = df.copy()\n",
        "df2['Is-IT-Job'] = False\n",
        "df2['keywords found'] = None\n",
        "def isIT_Job(targetCol = \"Sector\"):\n",
        "  pattern = re.compile(f\"{keywords[targetCol]}\")\n",
        "  for index in range(len(df2)):\n",
        "    try:\n",
        "      if len(pattern.findall(df2.iloc[index][targetCol])) >= 5 and targetCol == \"Job Description\":\n",
        "        df2['Is-IT-Job'][index] = True\n",
        "        df2['keywords found'][index] = set(pattern.findall(df2.iloc[index][targetCol]))\n",
        "      elif pattern.findall(df2.iloc[index][targetCol]) and targetCol == \"Sector\":\n",
        "        df2['Is-IT-Job'][index] = True\n",
        "        df2['keywords found'][index] = set(pattern.findall(df2.iloc[index][targetCol]))\n",
        "    except TypeError:\n",
        "      pass\n",
        "isIT_Job()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiDdtLAdc5ZG",
        "outputId": "5c9295c3-2df4-4638-8477-515cd4fd2ef5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df2[df2['Is-IT-Job'] == True]"
      ],
      "metadata": {
        "id": "vfBu8DJy2J82"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% **TRANSLATOR SECTION** %%%%%%%%%%%%%%%%%%%%%"
      ],
      "metadata": {
        "id": "QtV0Ih9dQYTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from starlette.responses import HTMLResponse\n",
        "# try api \n",
        "app = FastAPI(title = 'display dataframe')\n",
        "@app.get(\"/IT\")\n",
        "def show_it_jobs(orient:str='split'):\n",
        "  return Response(df2.to_json(orient = orient), media_type = \"application/json\")\n",
        "\n",
        "@app.get(\"/all_info\")\n",
        "def show_it_jobs(orient:str='split'):\n",
        "  return Response(df.to_json(orient = orient), media_type = \"application/json\")\n",
        "\n",
        "@app.get(\"/umucyo\")\n",
        "def show_it_jobs(orient:str='split'):\n",
        "  return Response(df.to_json(orient = orient), media_type = \"application/json\")\n",
        "\n",
        "model = EasyNMT(\"opus-mt\")\n",
        "@app.get(\"/translate\", response_class = HTMLResponse)\n",
        "def support_langs(lang:str=''):\n",
        "  if not lang:\n",
        "    with open('/content/drive/MyDrive/NLP fellowship/files/langs.json', 'r') as f:\n",
        "      content = f.read()\n",
        "      json_str = json.loads(content)\n",
        "    return Response(content, media_type = \"application/json\")\n",
        "  else:\n",
        "    previous_lang = 'en'\n",
        "    for row in range(len(df2)):\n",
        "      try:\n",
        "        df2['Job Description'][row] = model.translate([df2.iloc[row]['Job Description']], source_lang = previous_lang, target_lang=lang)\n",
        "        df2['Job Title'][row] = model.translate([df2.iloc[row]['Job Title']], source_lang = 'en', target_lang=lang)\n",
        "        previous_lang = lang\n",
        "      except AttributeError:\n",
        "        message = f\"\"\"<html>\n",
        "                      <h1>{lang} is not among the languages supported by easyNMT.<br>Try another language</h1>\n",
        "                      </html>\n",
        "                    \"\"\"\n",
        "        return HTMLResponse(message)\n",
        "      return Response(df2.to_json(orient = 'index'), media_type = 'application/json')\n",
        "    \n",
        "      "
      ],
      "metadata": {
        "id": "H9JCM6scwblK"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.iloc[4]['Job Description']"
      ],
      "metadata": {
        "id": "FmPvI-F37d9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print(\"[REST API STARTED]\")\n",
        "print(\"[YOUR PUCLIC API URL]: \", ngrok_tunnel.public_url)\n",
        "# \n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port = 8000)"
      ],
      "metadata": {
        "id": "b_kbcZhBxO27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class translator:\n",
        "  def __init__(self):\n",
        "    # INITIALIZE THE MODEL FOR TRANSLATE\n",
        "    self.model = EasyNMT(\"opus-mt\")\n",
        "  \n",
        "  def supportedLangs(self, all_langs, supported):\n",
        "    with open(all_langs) as f_json:\n",
        "      content = f_json.read()\n",
        "    langs = json.loads(content)\n",
        "    print(\"langs: \", langs)\n",
        "\n",
        "    with open(supported) as f2_json:\n",
        "          content = f2_json.read()\n",
        "    supplangs = json.loads(content)\n",
        "    supp_codes = set(list(langs.values())).intersection(set(supplangs))\n",
        "    supp_keyValue = {}\n",
        "    for key in langs.keys():\n",
        "      if langs[key] in supp_codes:\n",
        "        supp_keyValue[key] = langs[key]\n",
        "    return supp_keyValue\n",
        "    \n",
        "\n",
        "  def translate(self, sentences, targetLang, source = 'en', single = True):\n",
        "    fail_message = \"[FAIL]: destination lang is not a suported language by the model\"\n",
        "    success = 0\n",
        "    if single:\n",
        "      try:\n",
        "        translation = self.model.translate(sentences, source_lang = source, target_lang = targetLang)\n",
        "        return translation\n",
        "      except:\n",
        "        print(fail_message)\n",
        "    else:\n",
        "      translated = []\n",
        "      for target in targetLang:\n",
        "        try:\n",
        "          translation = self.model.translate(sentences, source_lang = source, target_lang = target)\n",
        "          translated.append(translation)\n",
        "          success += 1\n",
        "        except:\n",
        "          print(fail_message)\n",
        "      return translated, success\n"
      ],
      "metadata": {
        "id": "45mswuggQdOq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "nest_asyncio : helps to make fastapi asynchronous"
      ],
      "metadata": {
        "id": "po4P5aEPh_Hb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def umucyo_data():\n",
        "  c = \"https://www.umucyo.gov.rw/eb/bav/selectListAdvertisingListForGU.do\"\n",
        "  s = bs(requests.get(c).content, 'html.parser')\n",
        "  table = s.find('table', class_ = \"article_table mb10\")\n",
        "  heads = [re.compile('[\\r|\\n|\\t]+').sub('#', head.text.strip()) for head in table.find_all('thead')]\n",
        "  heads = heads[0].split('#')\n",
        "  rows = table.find_all('tr')\n",
        "  full = [[detail.text.strip() for detail in row.find_all('td')][1:] for row in rows]\n",
        "\n",
        "  # df\n",
        "  return pd.DataFrame(full, columns = heads)"
      ],
      "metadata": {
        "id": "xU4OYJ3MNhFZ"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}