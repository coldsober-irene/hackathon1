{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPactFGfsd33zA+5Z4vuYa1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coldsober-irene/hackathon1/blob/main/Copy_of_hackathon1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  -U easynmt"
      ],
      "metadata": {
        "id": "odThOZlgRGDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VVznFQk0ndVF"
      },
      "outputs": [],
      "source": [
        "# REQUIRED IMPORTS\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import requests\n",
        "import pandas as pd\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "from easynmt import EasyNMT\n",
        "import json # to access languages codes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% **WEBSCRAPING SECTION** %%%%%%%%%%%%%%%%%%%%%"
      ],
      "metadata": {
        "id": "sf_tJz_GQfY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA MINING\n",
        "class dataMining:\n",
        "  def __init__(self, jobSource = \"Job In Rwanda\"):\n",
        "    self.source = jobSource\n",
        "    self.jobIdentification = {} # {\"software_developer\":[published_date, company, requirements, deadline, full_description],....}\n",
        "  \n",
        "  # SOUP\n",
        "  def Soup(self, url):\n",
        "    page = requests.get(url).content\n",
        "    soup = bs(page, \"html.parser\")\n",
        "    return soup\n",
        "\n",
        "  def get_links(self):\n",
        "    # GET SOUP OBJECT\n",
        "    soup = self.Soup(url = \"https://www.jobinrwanda.com/jobs/all\")\n",
        "    # GET ALL JOBS LINKS\n",
        "    company_infoLink = []\n",
        "    \n",
        "    all_jobsLinks = [\"https://www.jobinrwanda.com\"+link['href'] if \"job\" in link['href'] \n",
        "                     else company_infoLink.append(link.text) \n",
        "                     for div in soup.find_all(\"div\", class_= \"card-body p-2\") \n",
        "                     for link in div.find_all(\"a\")\n",
        "                     ]\n",
        "    all_jobsLinks = [link for link in all_jobsLinks if link]\n",
        "    return (all_jobsLinks, company_infoLink)\n",
        "\n",
        "  def get_jobInfo(self):\n",
        "    jobLinks = self.get_links()[0]\n",
        "    info = {}\n",
        "    # REFINE THE INFO INTO A DICTIONARY\n",
        "    def refine_info(ls):\n",
        "      refined_info = {}\n",
        "      infoZeroPattern = re.compile(\"\\d+.*\")\n",
        "      views = infoZeroPattern.search(ls[0]).group()\n",
        "      refined_info[\"views\"] = views\n",
        "      # OTHER DETAILS EXCEPT THE ONE ON POSITION 0\n",
        "      otherInfoPattern = re.compile(\":\")\n",
        "      for detail in ls[1:]:\n",
        "        if detail.lower() == \"apply\":\n",
        "          pass\n",
        "        else:\n",
        "          try:\n",
        "            detailed = otherInfoPattern.split(detail)\n",
        "            refined_info[detailed[0]] = detailed[1]\n",
        "          except IndexError:\n",
        "            pass\n",
        "      return refined_info\n",
        "       \n",
        "    for index,url in enumerate(jobLinks):\n",
        "      soup = self.Soup(url)\n",
        "      pattern = re.compile(\"\\s{2,}\")\n",
        "      job_info = [pattern.sub(\" \",li.text.strip().replace(\"\\n\", \"\")) for ul in soup.find_all('ul', class_ = \"list-group list-group-flush\") \n",
        "      for li in ul.find_all('li')]\n",
        "      # DICTIONANRY OF INFO\n",
        "      info[index] = refine_info(job_info[:9])\n",
        "    return info\n",
        "\n",
        "  def get_description(self):\n",
        "    jobLinks = self.get_links()[0]\n",
        "    all_text= {}\n",
        "    for index,link in enumerate(jobLinks):\n",
        "      soup = self.Soup(link)\n",
        "      # JOB TITLE\n",
        "      job_title = soup.find('span', class_ = \"field field--name-title field--type-string field--label-hidden\")\n",
        "      \n",
        "      tags_content = soup.find_all('div', class_= \"clearfix text-formatted field field--name-field-job-full-description field--type-text-long field--label-hidden field__item\")\n",
        "      \n",
        "      for div in tags_content:\n",
        "        temp = []\n",
        "        try:\n",
        "          # GET APPLICATION LINK\n",
        "          app_link = soup.find(\"a\", class_ = \"btn btn-sm btn-success\")['href']\n",
        "          if app_link.startswith(\"/\"):\n",
        "            app_link = \"https://www.jobinrwanda.com\"+app_link\n",
        "          temp.append(app_link)\n",
        "          \n",
        "        except TypeError:\n",
        "          temp.append(np.nan)\n",
        "        for tag in div.children:\n",
        "          try:\n",
        "            temp.append(tag.get_text())\n",
        "          except (AttributeError, TypeError):\n",
        "            pass\n",
        "        temp.insert(0, job_title.text)\n",
        "        all_text[index] = temp\n",
        "    return all_text\n"
      ],
      "metadata": {
        "id": "FHrZBDzxnr2Q"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CLASS OBJECT CREATION\n",
        "jobInRwanda = dataMining()\n",
        "job_text = jobInRwanda.get_description()"
      ],
      "metadata": {
        "id": "eYFQfdZGeGQo"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(job_text[0])"
      ],
      "metadata": {
        "id": "fJt50674epQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MERGE JOB DESCRIPTION WITH THE JOB INFO\n",
        "def final_textDemo():\n",
        "  global info\n",
        "  # CLASS OBJECT CREATION\n",
        "  jobInRwanda = dataMining()\n",
        "  job_text = jobInRwanda.get_description()\n",
        "  info = jobInRwanda.get_jobInfo()\n",
        "\n",
        "  final_demo = []\n",
        "  for index in list(info.keys()):\n",
        "    info_value = list(info[index].values())\n",
        "    # ADD COMPANY HIRING\n",
        "    co_info = jobInRwanda.get_links()[1]\n",
        "    info_value.append(co_info[index])\n",
        "    # INCLUDE JOB TITLE\n",
        "    info_value.append(job_text[index][0])\n",
        "    # INCLUDE APPLY LINK\n",
        "    info_value.append(job_text[index][1])\n",
        "    # JOIN PARAGRAPHS \n",
        "    t = '\\n'.join(job_text[index][2:])\n",
        "    g = re.compile(\"\\n|\\\\xa0\").sub(\"\", t)\n",
        "    info_value.append(g)\n",
        "    final_demo.append(info_value)\n",
        "    \n",
        "  return final_demo"
      ],
      "metadata": {
        "id": "6M1vZYI28KaD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# job_details = final_textDemo()"
      ],
      "metadata": {
        "id": "0sUkUZkqyKiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def makeDataFrame(dataList, columns):\n",
        "  return pd.DataFrame(dataList, columns = columns)"
      ],
      "metadata": {
        "id": "lcrB0k65le1W"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATAFRAME FORMED\n",
        "titles = list(info[0].keys()) + [\"Company Hiring\",'Job Title', \"Application link\", \"Job Description\"]\n",
        "df = makeDataFrame(final_textDemo(), titles)\n"
      ],
      "metadata": {
        "id": "zlSrP6K6w6ZR"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(30)"
      ],
      "metadata": {
        "id": "88w4gLIT1MGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA PRESENTATION\n",
        "ITkeywords = [\"Computer and IT\", \"\"]"
      ],
      "metadata": {
        "id": "OiOwDk__n0NH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% **TRANSLATOR SECTION** %%%%%%%%%%%%%%%%%%%%%"
      ],
      "metadata": {
        "id": "QtV0Ih9dQYTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class translator:\n",
        "  def __init__(self):\n",
        "    # INITIALIZE THE MODEL FOR TRANSLATE\n",
        "    self.model = EasyNMT(\"opus-mt\")\n",
        "  \n",
        "  def supportedLangs(self, all_langs, supported):\n",
        "    with open(all_langs) as f_json:\n",
        "      content = f_json.read()\n",
        "    langs = json.loads(content)\n",
        "\n",
        "    with open(supported) as f2_json:\n",
        "          content = f2_json.read()\n",
        "    supplangs = json.loads(content)\n",
        "    supp_codes = set(list(langs.values())).intersection(set(supplangs))\n",
        "    supp_keyValue = {}\n",
        "    for key in langs.keys():\n",
        "      if langs[key] in supp_codes:\n",
        "        supp_keyValue[key] = langs[key]\n",
        "    return supp_keyValue\n",
        "    \n",
        "\n",
        "  def translate(self, sentences, targetLang, source = 'en', single = True):\n",
        "    fail_message = \"[FAIL]: destination lang is not a suported language by the model\"\n",
        "    success = 0\n",
        "    if single:\n",
        "      try:\n",
        "        translation = self.model.translate(sentences, source_lang = source, target_lang = targetLang)\n",
        "        return translation\n",
        "      except:\n",
        "        print(fail_message)\n",
        "    else:\n",
        "      translated = []\n",
        "      for target in targetLang:\n",
        "        try:\n",
        "          translation = self.model.translate(sentences, source_lang = source, target_lang = target)\n",
        "          translated.append(translation)\n",
        "          success += 1\n",
        "        except:\n",
        "          print(fail_message)\n",
        "      return translated, success\n"
      ],
      "metadata": {
        "id": "45mswuggQdOq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}